import numpy as np
import matplotlib.pyplot as plt

def MWC(x):
    a = 3947008974
    x = a*(x & (2**32 - 1)) + (x >> 32)
    return x
    
def XOR_shift(x):
    a1, a2, a3 = np.uint64(21), np.uint64(35), np.uint64(4)
    x = np.uint64(x)
    x = x ^ (x >> a1)
    x = x ^ (x << a2)
    x = x ^ (x >> a3)
    return x

def RNG(length, norm = True):
    global seed

    randomnumbers = []
    state = seed
   
    for i in range(length):
        state = MWC(state)
        randomnumbers.append(XOR_shift(state))

    randomnumbers = np.array(randomnumbers)

    if norm == True:
        randomnumbers = np.array(randomnumbers)/(2**64)

    seed = state
    if length == 1:
        return randomnumbers[0]
    else:
        return randomnumbers.tolist()

def gaussian(x, alpha):
    return np.exp(-alpha*(x**2))

def intfunc(x, alpha):
    return np.exp(-alpha*(x**2)) + np.exp(-alpha/(x**2))/(x**2)

def extmidpoint(func, edges, n, **kwargs):
    h = (edges[1]-edges[0])/n
    integration = 0

    for i in range(n):
        integration += func(edges[0]+(i+0.5)*h, **kwargs)
    integration = h*integration

    return integration

def extmidpointromberg(func, edges, n, N, **kwargs):
    s = [[] for i in range(N)]
    s[0].append(extmidpoint(func, edges, n, **kwargs))

    for i in range (1,N):
        n = 2*n
        s[0].append(extmidpoint(func, edges, n, **kwargs))
   
    for j in range(N-1):
        for i in range(N-(j+1)):
            s[j+1].append(s[j][i+1]+(s[j][i+1]-s[j][i])/(-1+4**(j+1)))

    return s[-1][0]

def Box_Muller(size, mu, sigma):
    
    if size%2 == 0:
        halfsize = int(0.5*size)
    else:
        halfsize = int(0.5*(size+1))

    u1, u2 = np.array(RNG(halfsize)), np.array(RNG(halfsize))
    theta = 2*np.pi*u1
    r = (-2*(sigma**2)*np.log(u2))**0.5
    x = mu + r*np.cos(theta)
    y = mu + r*np.sin(theta)

    return np.append(x, y)[0:size]

def Gaussian(x, mu, sigma):
    return (1/(2*np.pi*(sigma**2))**0.5)*np.exp(-(x-mu)**2/(2*(sigma**2)))

def Erf(x):
    return (2/(np.pi**0.5))*extmidpointromberg(lambda t: np.exp(-t**2), [0,x], 100, 4)

def Gaussian_CDF(x, mu, sigma):
    return 0.5*(1+Erf((x-mu)/(sigma*(2**0.5))))

def argsort(x):
    if type(x) is np.ndarray:
        xd = x[:].tolist() #Create a copy of the array so the actual array doesn't get sorted
    else:
        xd = x[:]
    y = [i for i in range(len(x))]
    argsortinner(xd,y)
    return y

def argsortinner(xd, y, start=0, end=None): #When sorting the array, also keeps track of how the indices swap around
    if end == None:
        end = len(xd)-1
    if start < end:
        index = argpivotsort(xd,y,start,end)
        argsortinner(xd,y,start,index-1)
        argsortinner(xd,y,index+1,end)

def argpivotsort(xd,y,start,end):
    pivot = xd[end]
    i = start-1
    for j in range(start,end):
        if xd[j] <= pivot:
            i += 1
            xd[i], xd[j] = xd[j], xd[i]
            y[i], y[j] = y[j], y[i]
    xd[i+1], xd[end] = xd[end], xd[i+1]
    y[i+1], y[end] = y[end], y[i+1]
    return i+1

def pivotsort(x,start,end):
    pivot = x[end]
    i = start-1
    for j in range(start,end):
        if x[j] <= pivot:
            i += 1
            x[i], x[j] = x[j], x[i]
    x[i+1], x[end] = x[end], x[i+1]
    return i+1

def Quicksort(x, start=0, end=None):
    if end == None:
        end = len(x)-1
    if start < end:
        index = pivotsort(x,start,end)
        Quicksort(x,start,index-1)
        Quicksort(x,index+1,end)

def Compute_step_CDF(pdf):
    sortedpdf = pdf[argsort(pdf)]

    for value in sortedpdf:
        #Find way to compute CDF by making np.hist
        
    return step_CDF

def KS_test(pdf):
    step_CDF = compute_step_CDF(pdf)

    D = 0

    for value in step_CDF:
        if (value - Gaussian_CDF(x, 3, 2.4)) > D**2:
            D = (value - Gaussian_CDF(x, 3, 2.4))

    #Compare each value of the CDF with the theoretical CDF.
        
    return D

if __name__ == '__main__':
    seed = 67
    print("The seed has been set to: " + str(seed))

    """
    We create two lists using the RNG method where we compose the lists using our RNG method using only a MWC method composed with a 64-bit XOR_shift.
    We could use a new RNG method that combines different methods in a non-linear fashion. See the book for a better combination method: Ran.
    """

    RNG_list = RNG(1000)
    RNG_list2 = RNG(10**6)

    n_RNG_list = np.array(RNG_list[:-1])
    np1_RNG_list = np.array(RNG_list[1:])

    fig, axs = plt.subplots(1, 3, sharey=False, figsize=(15,15))

    axs[0].scatter(n_RNG_list, np1_RNG_list, marker="o", color=(1,0,0), facecolors='none')
    axs[1].plot(range(1000), RNG_list)
    axs[2].hist(RNG_list2, bins = 20, range = (0,1))

    xlabel = ['Combined RNG n', 'Index number', 'Random number generated by combined RNG']
    ylabel = ['Combined RNG n+1', 'Value RNG', 'Counts']

    i=0
    for ax in axs:
        ax.set(xlabel=xlabel[i], ylabel=ylabel[i])
        i+=1

    fig.savefig('./plots/RNG-test-results')

    """
    For Question 1b) we will integrate the Gaussian integral using the simplification specified in the PDF. We will use Romberg integration since it is very efficient.
    Unclear what method they expect us to use to fit a line through the 21 obtained integrated points. My guess would be something of the form (alpha/x)**0.5 and then using
    least squares or some bayesian fitting method to get the alpha.
    """
    
    integrationpoints = [2*extmidpointromberg(intfunc, [0,1], 100, 4, alpha=2**i) for i in range(-10,11)]
    
    fig2, axs2 = plt.subplots()
    axs2.scatter([2**i for i in range(-10,11)], integrationpoints, s=0.1, label='Extended midpoint Romberg', color = (1,0,0))
    axs2.scatter([2**i for i in range(-10,11)], [(np.pi/(2**i))**0.5 for i in range(-10,11)], s=0.1, label='Exact points', color = (0,1,0))
    axs2.set(xlabel='alpha', ylabel='integral')
    axs2.legend()
    fig2.savefig('./plots/gaussianintegral')

    """
    For Question 1c) Box Muller method can be found in 7.3.4 of the book. Does not seem to be anywhere in the slides.
    Are we allowed to use np.cos and np.sin and np.log? Seed and state need to be updated properly, because getting the same RNG number lists gives the wrong results.
    Furthermore the transformations we used below only work for getting a gaussian distribution with mu=0 and sigma=1. We need to figure out how to transform properly
    so we can get any specific form for the gaussian. Also change the graph to what they ask for.
    """

    xc = Box_Muller(1000,3,2.4)
    xcrange = np.linspace(3-5*2.4,3+5*2.4,100)
    
    fig3, axs3 = plt.subplots()

    axs3.hist(xc, bins=100, density=True)#weights=np.full(1000,(1/1000)))
    axs3.plot(xcrange, Gaussian(xcrange, 3, 2.4), color='r', label='Gaussian pdf')
    actual_stds = np.array(range(-4,5))*np.var(xc)**0.5+np.mean(xc)
    for line in actual_stds:
        axs3.axvline(x=line, color='b')

    theoretical_stds = np.array(range(-4,5))*2.4+3
    for line in theoretical_stds:
        axs3.axvline(x=line, color='g')

    axs3.set(xlabel='x', ylabel='count')
    axs3.legend()

    fig3.savefig('./plots/histogram-gaussian-distribution')

    """
    For Question 1d) look at the details of lecture 8.
    """
    
    gaussianarray = [Box_Muller(int(10**(1+0.1*i)),0,1) for i in range(41)]

    """
    sortedpdf = Quicksort(gaussianarray[0])
    for every_value in sortedpdf:
        calculate CDF by summing up 1/(size*width) for every value < x. Basicly integrating a discrete PDF to get a discrete CDF.

    After having obtained the discrete CDF. I can compare all the values of the discrete CDF to the theoretical CDF and determine the greatest distance.
    Once I have the greatest distance D, I can use the equation: Q_KS(sqrt(Ne) + 0.12 + ...) to the get P(D>observed) and plot these values for each dex.
    """
    
    #Probbiggerthanobserved = KS-test(D*(Ne**0.5+0.12+0.11/(Ne**0.5)))
